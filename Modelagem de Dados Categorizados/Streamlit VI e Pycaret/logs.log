2025-08-06 15:52:33,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 15:52:33,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 15:52:33,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 15:52:33,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 17:27:50,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 17:27:50,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 17:27:50,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 17:27:50,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-06 17:27:51,776:INFO:PyCaret RegressionExperiment
2025-08-06 17:27:51,776:INFO:Logging name: reg-default-name
2025-08-06 17:27:51,776:INFO:ML Usecase: MLUsecase.REGRESSION
2025-08-06 17:27:51,776:INFO:version 3.3.2
2025-08-06 17:27:51,776:INFO:Initializing setup()
2025-08-06 17:27:51,776:INFO:self.USI: 3658
2025-08-06 17:27:51,776:INFO:self._variable_keys: {'y_train', 'X_train', 'fold_shuffle_param', 'data', 'memory', 'fold_groups_param', 'exp_name_log', 'idx', 'X_test', 'y_test', 'y', '_ml_usecase', 'gpu_n_jobs_param', 'html_param', 'seed', 'X', 'logging_param', 'exp_id', 'USI', 'gpu_param', 'transform_target_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'pipeline'}
2025-08-06 17:27:51,776:INFO:Checking environment
2025-08-06 17:27:51,776:INFO:python_version: 3.11.7
2025-08-06 17:27:51,776:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-08-06 17:27:51,776:INFO:machine: AMD64
2025-08-06 17:27:51,776:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-06 17:27:51,776:INFO:Memory: svmem(total=8474312704, available=1215275008, percent=85.7, used=7259037696, free=1215275008)
2025-08-06 17:27:51,776:INFO:Physical Core: 2
2025-08-06 17:27:51,776:INFO:Logical Core: 4
2025-08-06 17:27:51,776:INFO:Checking libraries
2025-08-06 17:27:51,776:INFO:System:
2025-08-06 17:27:51,776:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-08-06 17:27:51,776:INFO:executable: c:\Users\nobre\anaconda3\python.exe
2025-08-06 17:27:51,776:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-06 17:27:51,776:INFO:PyCaret required dependencies:
2025-08-06 17:27:54,826:INFO:                 pip: 23.3.1
2025-08-06 17:27:54,826:INFO:          setuptools: 68.2.2
2025-08-06 17:27:54,826:INFO:             pycaret: 3.3.2
2025-08-06 17:27:54,826:INFO:             IPython: 8.20.0
2025-08-06 17:27:54,826:INFO:          ipywidgets: 7.6.5
2025-08-06 17:27:54,826:INFO:                tqdm: 4.65.0
2025-08-06 17:27:54,826:INFO:               numpy: 1.26.4
2025-08-06 17:27:54,826:INFO:              pandas: 2.1.4
2025-08-06 17:27:54,826:INFO:              jinja2: 3.1.3
2025-08-06 17:27:54,826:INFO:               scipy: 1.11.4
2025-08-06 17:27:54,826:INFO:              joblib: 1.2.0
2025-08-06 17:27:54,826:INFO:             sklearn: 1.4.2
2025-08-06 17:27:54,826:INFO:                pyod: 2.0.2
2025-08-06 17:27:54,826:INFO:            imblearn: 0.12.4
2025-08-06 17:27:54,826:INFO:   category_encoders: 2.6.4
2025-08-06 17:27:54,826:INFO:            lightgbm: 4.4.0
2025-08-06 17:27:54,826:INFO:               numba: 0.59.0
2025-08-06 17:27:54,826:INFO:            requests: 2.32.3
2025-08-06 17:27:54,826:INFO:          matplotlib: 3.7.5
2025-08-06 17:27:54,826:INFO:          scikitplot: 0.3.7
2025-08-06 17:27:54,826:INFO:         yellowbrick: 1.5
2025-08-06 17:27:54,826:INFO:              plotly: 5.24.1
2025-08-06 17:27:54,826:INFO:    plotly-resampler: Not installed
2025-08-06 17:27:54,826:INFO:             kaleido: 0.2.1
2025-08-06 17:27:54,826:INFO:           schemdraw: 0.15
2025-08-06 17:27:54,826:INFO:         statsmodels: 0.14.0
2025-08-06 17:27:54,826:INFO:              sktime: 0.26.0
2025-08-06 17:27:54,826:INFO:               tbats: 1.1.3
2025-08-06 17:27:54,826:INFO:            pmdarima: 2.0.4
2025-08-06 17:27:54,826:INFO:              psutil: 5.9.0
2025-08-06 17:27:54,826:INFO:          markupsafe: 2.1.3
2025-08-06 17:27:54,826:INFO:             pickle5: Not installed
2025-08-06 17:27:54,826:INFO:         cloudpickle: 2.2.1
2025-08-06 17:27:54,826:INFO:         deprecation: 2.1.0
2025-08-06 17:27:54,826:INFO:              xxhash: 3.5.0
2025-08-06 17:27:54,826:INFO:           wurlitzer: 3.1.1
2025-08-06 17:27:54,826:INFO:PyCaret optional dependencies:
2025-08-06 17:27:55,125:INFO:                shap: Not installed
2025-08-06 17:27:55,125:INFO:           interpret: Not installed
2025-08-06 17:27:55,125:INFO:                umap: Not installed
2025-08-06 17:27:55,125:INFO:     ydata_profiling: 4.12.0
2025-08-06 17:27:55,125:INFO:  explainerdashboard: Not installed
2025-08-06 17:27:55,125:INFO:             autoviz: Not installed
2025-08-06 17:27:55,125:INFO:           fairlearn: Not installed
2025-08-06 17:27:55,125:INFO:          deepchecks: Not installed
2025-08-06 17:27:55,125:INFO:             xgboost: 2.1.0
2025-08-06 17:27:55,125:INFO:            catboost: Not installed
2025-08-06 17:27:55,125:INFO:              kmodes: Not installed
2025-08-06 17:27:55,125:INFO:             mlxtend: Not installed
2025-08-06 17:27:55,125:INFO:       statsforecast: Not installed
2025-08-06 17:27:55,125:INFO:        tune_sklearn: Not installed
2025-08-06 17:27:55,125:INFO:                 ray: Not installed
2025-08-06 17:27:55,125:INFO:            hyperopt: Not installed
2025-08-06 17:27:55,125:INFO:              optuna: Not installed
2025-08-06 17:27:55,125:INFO:               skopt: Not installed
2025-08-06 17:27:55,125:INFO:              mlflow: Not installed
2025-08-06 17:27:55,125:INFO:              gradio: Not installed
2025-08-06 17:27:55,125:INFO:             fastapi: Not installed
2025-08-06 17:27:55,125:INFO:             uvicorn: Not installed
2025-08-06 17:27:55,125:INFO:              m2cgen: Not installed
2025-08-06 17:27:55,125:INFO:           evidently: Not installed
2025-08-06 17:27:55,125:INFO:               fugue: Not installed
2025-08-06 17:27:55,125:INFO:           streamlit: 1.30.0
2025-08-06 17:27:55,125:INFO:             prophet: Not installed
2025-08-06 17:27:55,125:INFO:None
2025-08-06 17:27:55,125:INFO:Set up data.
2025-08-06 17:27:55,707:INFO:Set up folding strategy.
2025-08-06 17:27:55,707:INFO:Set up train/test split.
2025-08-06 17:27:55,876:INFO:Set up index.
2025-08-06 17:27:55,907:INFO:Assigning column types.
2025-08-06 17:27:56,038:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-06 17:27:56,038:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,038:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,392:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:56,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:56,392:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,392:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,771:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:56,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:56,771:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-08-06 17:27:56,771:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 17:27:56,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,127:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:57,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:57,127:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,474:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:57,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:57,490:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-08-06 17:27:57,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:57,822:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:57,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:57,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,170:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:58,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:58,185:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-08-06 17:27:58,491:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,559:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:58,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:58,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 17:27:58,904:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:58,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:58,919:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-06 17:27:59,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:59,289:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:59,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:59,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 17:27:59,654:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:27:59,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:27:59,654:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-08-06 17:28:00,024:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:28:00,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:28:00,424:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:28:00,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:28:00,440:INFO:Preparing preprocessing pipeline...
2025-08-06 17:28:00,440:INFO:Set up simple imputation.
2025-08-06 17:28:00,588:INFO:Set up encoding of ordinal features.
2025-08-06 17:28:00,672:INFO:Set up encoding of categorical features.
2025-08-06 17:28:05,552:INFO:Finished creating preprocessing pipeline.
2025-08-06 17:28:05,583:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nobre\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sexo', 'qtd_filhos', 'idade',
                                             'qt_pessoas_residencia', 'renda',
                                             'mau'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['posse_de_veiculo',
                                             'posse_de_imovel', 'tipo_renda',
                                             'educacao', 'estado...
S      1
NaN   -1
dtype: int64},
                                                                        {'col': 'posse_de_imovel',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': N      0
S      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-08-06 17:28:05,583:INFO:Creating final display dataframe.
2025-08-06 17:28:12,832:INFO:Setup _display_container:                     Description             Value
0                    Session id                23
1                        Target     tempo_emprego
2                   Target type        Regression
3           Original data shape      (624043, 13)
4        Transformed data shape      (624043, 30)
5   Transformed train set shape      (436830, 30)
6    Transformed test set shape      (187213, 30)
7              Numeric features                 6
8          Categorical features                 6
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              3658
2025-08-06 17:28:13,414:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:28:13,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:28:13,765:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 17:28:13,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 17:28:13,782:INFO:setup() successfully completed in 22.01s...............
2025-08-06 17:31:48,625:INFO:Initializing compare_models()
2025-08-06 17:31:48,626:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-08-06 17:31:48,626:INFO:Checking exceptions
2025-08-06 17:31:48,883:INFO:Preparing display monitor
2025-08-06 17:31:48,967:INFO:Initializing Linear Regression
2025-08-06 17:31:48,967:INFO:Total runtime is 0.0 minutes
2025-08-06 17:31:48,989:INFO:SubProcess create_model() called ==================================
2025-08-06 17:31:48,990:INFO:Initializing create_model()
2025-08-06 17:31:48,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:31:48,992:INFO:Checking exceptions
2025-08-06 17:31:48,992:INFO:Importing libraries
2025-08-06 17:31:48,992:INFO:Copying training dataset
2025-08-06 17:31:49,924:INFO:Defining folds
2025-08-06 17:31:49,925:INFO:Declaring metric variables
2025-08-06 17:31:49,937:INFO:Importing untrained model
2025-08-06 17:31:49,957:INFO:Linear Regression Imported successfully
2025-08-06 17:31:49,998:INFO:Starting cross validation
2025-08-06 17:31:50,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:33:03,576:INFO:Calculating mean and std
2025-08-06 17:33:03,582:INFO:Creating metrics dataframe
2025-08-06 17:33:03,582:INFO:Uploading results into container
2025-08-06 17:33:03,582:INFO:Uploading model into container now
2025-08-06 17:33:03,582:INFO:_master_model_container: 1
2025-08-06 17:33:03,582:INFO:_display_container: 2
2025-08-06 17:33:03,582:INFO:LinearRegression(n_jobs=-1)
2025-08-06 17:33:03,582:INFO:create_model() successfully completed......................................
2025-08-06 17:33:03,932:INFO:SubProcess create_model() end ==================================
2025-08-06 17:33:03,932:INFO:Creating metrics dataframe
2025-08-06 17:33:03,955:INFO:Initializing Lasso Regression
2025-08-06 17:33:03,955:INFO:Total runtime is 1.24980521996816 minutes
2025-08-06 17:33:03,970:INFO:SubProcess create_model() called ==================================
2025-08-06 17:33:03,971:INFO:Initializing create_model()
2025-08-06 17:33:03,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:33:03,971:INFO:Checking exceptions
2025-08-06 17:33:03,971:INFO:Importing libraries
2025-08-06 17:33:03,972:INFO:Copying training dataset
2025-08-06 17:33:04,699:INFO:Defining folds
2025-08-06 17:33:04,699:INFO:Declaring metric variables
2025-08-06 17:33:04,717:INFO:Importing untrained model
2025-08-06 17:33:04,749:INFO:Lasso Regression Imported successfully
2025-08-06 17:33:04,778:INFO:Starting cross validation
2025-08-06 17:33:04,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:33:36,535:INFO:Calculating mean and std
2025-08-06 17:33:36,535:INFO:Creating metrics dataframe
2025-08-06 17:33:36,535:INFO:Uploading results into container
2025-08-06 17:33:36,535:INFO:Uploading model into container now
2025-08-06 17:33:36,535:INFO:_master_model_container: 2
2025-08-06 17:33:36,535:INFO:_display_container: 2
2025-08-06 17:33:36,535:INFO:Lasso(random_state=23)
2025-08-06 17:33:36,535:INFO:create_model() successfully completed......................................
2025-08-06 17:33:36,702:INFO:SubProcess create_model() end ==================================
2025-08-06 17:33:36,702:INFO:Creating metrics dataframe
2025-08-06 17:33:36,722:INFO:Initializing Ridge Regression
2025-08-06 17:33:36,722:INFO:Total runtime is 1.795919915040334 minutes
2025-08-06 17:33:36,734:INFO:SubProcess create_model() called ==================================
2025-08-06 17:33:36,734:INFO:Initializing create_model()
2025-08-06 17:33:36,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:33:36,734:INFO:Checking exceptions
2025-08-06 17:33:36,734:INFO:Importing libraries
2025-08-06 17:33:36,734:INFO:Copying training dataset
2025-08-06 17:33:37,238:INFO:Defining folds
2025-08-06 17:33:37,238:INFO:Declaring metric variables
2025-08-06 17:33:37,259:INFO:Importing untrained model
2025-08-06 17:33:37,271:INFO:Ridge Regression Imported successfully
2025-08-06 17:33:37,301:INFO:Starting cross validation
2025-08-06 17:33:37,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:34:07,619:INFO:Calculating mean and std
2025-08-06 17:34:07,619:INFO:Creating metrics dataframe
2025-08-06 17:34:07,619:INFO:Uploading results into container
2025-08-06 17:34:07,619:INFO:Uploading model into container now
2025-08-06 17:34:07,619:INFO:_master_model_container: 3
2025-08-06 17:34:07,619:INFO:_display_container: 2
2025-08-06 17:34:07,619:INFO:Ridge(random_state=23)
2025-08-06 17:34:07,619:INFO:create_model() successfully completed......................................
2025-08-06 17:34:07,736:INFO:SubProcess create_model() end ==================================
2025-08-06 17:34:07,736:INFO:Creating metrics dataframe
2025-08-06 17:34:07,753:INFO:Initializing Elastic Net
2025-08-06 17:34:07,755:INFO:Total runtime is 2.3131428837776182 minutes
2025-08-06 17:34:07,764:INFO:SubProcess create_model() called ==================================
2025-08-06 17:34:07,766:INFO:Initializing create_model()
2025-08-06 17:34:07,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:34:07,767:INFO:Checking exceptions
2025-08-06 17:34:07,768:INFO:Importing libraries
2025-08-06 17:34:07,768:INFO:Copying training dataset
2025-08-06 17:34:08,169:INFO:Defining folds
2025-08-06 17:34:08,169:INFO:Declaring metric variables
2025-08-06 17:34:08,190:INFO:Importing untrained model
2025-08-06 17:34:08,203:INFO:Elastic Net Imported successfully
2025-08-06 17:34:08,236:INFO:Starting cross validation
2025-08-06 17:34:08,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:34:37,926:INFO:Calculating mean and std
2025-08-06 17:34:37,926:INFO:Creating metrics dataframe
2025-08-06 17:34:37,938:INFO:Uploading results into container
2025-08-06 17:34:37,940:INFO:Uploading model into container now
2025-08-06 17:34:37,941:INFO:_master_model_container: 4
2025-08-06 17:34:37,941:INFO:_display_container: 2
2025-08-06 17:34:37,941:INFO:ElasticNet(random_state=23)
2025-08-06 17:34:37,941:INFO:create_model() successfully completed......................................
2025-08-06 17:34:38,056:INFO:SubProcess create_model() end ==================================
2025-08-06 17:34:38,056:INFO:Creating metrics dataframe
2025-08-06 17:34:38,079:INFO:Initializing Least Angle Regression
2025-08-06 17:34:38,079:INFO:Total runtime is 2.818545897801717 minutes
2025-08-06 17:34:38,095:INFO:SubProcess create_model() called ==================================
2025-08-06 17:34:38,095:INFO:Initializing create_model()
2025-08-06 17:34:38,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:34:38,095:INFO:Checking exceptions
2025-08-06 17:34:38,095:INFO:Importing libraries
2025-08-06 17:34:38,095:INFO:Copying training dataset
2025-08-06 17:34:38,472:INFO:Defining folds
2025-08-06 17:34:38,472:INFO:Declaring metric variables
2025-08-06 17:34:38,492:INFO:Importing untrained model
2025-08-06 17:34:38,510:INFO:Least Angle Regression Imported successfully
2025-08-06 17:34:38,534:INFO:Starting cross validation
2025-08-06 17:34:38,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:35:07,881:INFO:Calculating mean and std
2025-08-06 17:35:07,881:INFO:Creating metrics dataframe
2025-08-06 17:35:07,881:INFO:Uploading results into container
2025-08-06 17:35:07,881:INFO:Uploading model into container now
2025-08-06 17:35:07,881:INFO:_master_model_container: 5
2025-08-06 17:35:07,881:INFO:_display_container: 2
2025-08-06 17:35:07,890:INFO:Lars(random_state=23)
2025-08-06 17:35:07,890:INFO:create_model() successfully completed......................................
2025-08-06 17:35:08,059:INFO:SubProcess create_model() end ==================================
2025-08-06 17:35:08,059:INFO:Creating metrics dataframe
2025-08-06 17:35:08,064:INFO:Initializing Lasso Least Angle Regression
2025-08-06 17:35:08,064:INFO:Total runtime is 3.318285051981608 minutes
2025-08-06 17:35:08,075:INFO:SubProcess create_model() called ==================================
2025-08-06 17:35:08,075:INFO:Initializing create_model()
2025-08-06 17:35:08,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:35:08,075:INFO:Checking exceptions
2025-08-06 17:35:08,075:INFO:Importing libraries
2025-08-06 17:35:08,075:INFO:Copying training dataset
2025-08-06 17:35:08,525:INFO:Defining folds
2025-08-06 17:35:08,525:INFO:Declaring metric variables
2025-08-06 17:35:08,549:INFO:Importing untrained model
2025-08-06 17:35:08,560:INFO:Lasso Least Angle Regression Imported successfully
2025-08-06 17:35:08,601:INFO:Starting cross validation
2025-08-06 17:35:08,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:35:36,918:INFO:Calculating mean and std
2025-08-06 17:35:36,918:INFO:Creating metrics dataframe
2025-08-06 17:35:36,918:INFO:Uploading results into container
2025-08-06 17:35:36,918:INFO:Uploading model into container now
2025-08-06 17:35:36,918:INFO:_master_model_container: 6
2025-08-06 17:35:36,918:INFO:_display_container: 2
2025-08-06 17:35:36,918:INFO:LassoLars(random_state=23)
2025-08-06 17:35:36,918:INFO:create_model() successfully completed......................................
2025-08-06 17:35:37,033:INFO:SubProcess create_model() end ==================================
2025-08-06 17:35:37,033:INFO:Creating metrics dataframe
2025-08-06 17:35:37,055:INFO:Initializing Orthogonal Matching Pursuit
2025-08-06 17:35:37,055:INFO:Total runtime is 3.8014803369839982 minutes
2025-08-06 17:35:37,064:INFO:SubProcess create_model() called ==================================
2025-08-06 17:35:37,064:INFO:Initializing create_model()
2025-08-06 17:35:37,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:35:37,064:INFO:Checking exceptions
2025-08-06 17:35:37,064:INFO:Importing libraries
2025-08-06 17:35:37,064:INFO:Copying training dataset
2025-08-06 17:35:37,569:INFO:Defining folds
2025-08-06 17:35:37,569:INFO:Declaring metric variables
2025-08-06 17:35:37,585:INFO:Importing untrained model
2025-08-06 17:35:37,603:INFO:Orthogonal Matching Pursuit Imported successfully
2025-08-06 17:35:37,647:INFO:Starting cross validation
2025-08-06 17:35:37,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:36:05,439:INFO:Calculating mean and std
2025-08-06 17:36:05,439:INFO:Creating metrics dataframe
2025-08-06 17:36:05,439:INFO:Uploading results into container
2025-08-06 17:36:05,439:INFO:Uploading model into container now
2025-08-06 17:36:05,439:INFO:_master_model_container: 7
2025-08-06 17:36:05,439:INFO:_display_container: 2
2025-08-06 17:36:05,439:INFO:OrthogonalMatchingPursuit()
2025-08-06 17:36:05,439:INFO:create_model() successfully completed......................................
2025-08-06 17:36:05,566:INFO:SubProcess create_model() end ==================================
2025-08-06 17:36:05,566:INFO:Creating metrics dataframe
2025-08-06 17:36:05,590:INFO:Initializing Bayesian Ridge
2025-08-06 17:36:05,590:INFO:Total runtime is 4.277049895127614 minutes
2025-08-06 17:36:05,607:INFO:SubProcess create_model() called ==================================
2025-08-06 17:36:05,607:INFO:Initializing create_model()
2025-08-06 17:36:05,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:36:05,607:INFO:Checking exceptions
2025-08-06 17:36:05,607:INFO:Importing libraries
2025-08-06 17:36:05,607:INFO:Copying training dataset
2025-08-06 17:36:05,999:INFO:Defining folds
2025-08-06 17:36:05,999:INFO:Declaring metric variables
2025-08-06 17:36:06,024:INFO:Importing untrained model
2025-08-06 17:36:06,039:INFO:Bayesian Ridge Imported successfully
2025-08-06 17:36:06,080:INFO:Starting cross validation
2025-08-06 17:36:06,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:36:47,154:INFO:Calculating mean and std
2025-08-06 17:36:47,154:INFO:Creating metrics dataframe
2025-08-06 17:36:47,169:INFO:Uploading results into container
2025-08-06 17:36:47,170:INFO:Uploading model into container now
2025-08-06 17:36:47,171:INFO:_master_model_container: 8
2025-08-06 17:36:47,171:INFO:_display_container: 2
2025-08-06 17:36:47,171:INFO:BayesianRidge()
2025-08-06 17:36:47,171:INFO:create_model() successfully completed......................................
2025-08-06 17:36:47,348:INFO:SubProcess create_model() end ==================================
2025-08-06 17:36:47,348:INFO:Creating metrics dataframe
2025-08-06 17:36:47,363:INFO:Initializing Passive Aggressive Regressor
2025-08-06 17:36:47,363:INFO:Total runtime is 4.973278228441874 minutes
2025-08-06 17:36:47,385:INFO:SubProcess create_model() called ==================================
2025-08-06 17:36:47,385:INFO:Initializing create_model()
2025-08-06 17:36:47,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:36:47,386:INFO:Checking exceptions
2025-08-06 17:36:47,386:INFO:Importing libraries
2025-08-06 17:36:47,386:INFO:Copying training dataset
2025-08-06 17:36:47,865:INFO:Defining folds
2025-08-06 17:36:47,865:INFO:Declaring metric variables
2025-08-06 17:36:47,875:INFO:Importing untrained model
2025-08-06 17:36:47,885:INFO:Passive Aggressive Regressor Imported successfully
2025-08-06 17:36:47,922:INFO:Starting cross validation
2025-08-06 17:36:47,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:37:20,372:INFO:Calculating mean and std
2025-08-06 17:37:20,372:INFO:Creating metrics dataframe
2025-08-06 17:37:20,372:INFO:Uploading results into container
2025-08-06 17:37:20,372:INFO:Uploading model into container now
2025-08-06 17:37:20,390:INFO:_master_model_container: 9
2025-08-06 17:37:20,392:INFO:_display_container: 2
2025-08-06 17:37:20,394:INFO:PassiveAggressiveRegressor(random_state=23)
2025-08-06 17:37:20,394:INFO:create_model() successfully completed......................................
2025-08-06 17:37:20,519:INFO:SubProcess create_model() end ==================================
2025-08-06 17:37:20,519:INFO:Creating metrics dataframe
2025-08-06 17:37:20,535:INFO:Initializing Huber Regressor
2025-08-06 17:37:20,535:INFO:Total runtime is 5.5261330723762505 minutes
2025-08-06 17:37:20,535:INFO:SubProcess create_model() called ==================================
2025-08-06 17:37:20,550:INFO:Initializing create_model()
2025-08-06 17:37:20,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:37:20,550:INFO:Checking exceptions
2025-08-06 17:37:20,550:INFO:Importing libraries
2025-08-06 17:37:20,550:INFO:Copying training dataset
2025-08-06 17:37:20,959:INFO:Defining folds
2025-08-06 17:37:20,959:INFO:Declaring metric variables
2025-08-06 17:37:20,971:INFO:Importing untrained model
2025-08-06 17:37:20,984:INFO:Huber Regressor Imported successfully
2025-08-06 17:37:21,000:INFO:Starting cross validation
2025-08-06 17:37:21,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:38:43,515:WARNING:c:\Users\nobre\anaconda3\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-06 17:38:53,429:INFO:Calculating mean and std
2025-08-06 17:38:53,429:INFO:Creating metrics dataframe
2025-08-06 17:38:53,429:INFO:Uploading results into container
2025-08-06 17:38:53,429:INFO:Uploading model into container now
2025-08-06 17:38:53,429:INFO:_master_model_container: 10
2025-08-06 17:38:53,429:INFO:_display_container: 2
2025-08-06 17:38:53,429:INFO:HuberRegressor()
2025-08-06 17:38:53,429:INFO:create_model() successfully completed......................................
2025-08-06 17:38:53,557:INFO:SubProcess create_model() end ==================================
2025-08-06 17:38:53,557:INFO:Creating metrics dataframe
2025-08-06 17:38:53,576:INFO:Initializing K Neighbors Regressor
2025-08-06 17:38:53,576:INFO:Total runtime is 7.076817095279693 minutes
2025-08-06 17:38:53,593:INFO:SubProcess create_model() called ==================================
2025-08-06 17:38:53,594:INFO:Initializing create_model()
2025-08-06 17:38:53,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:38:53,594:INFO:Checking exceptions
2025-08-06 17:38:53,594:INFO:Importing libraries
2025-08-06 17:38:53,595:INFO:Copying training dataset
2025-08-06 17:38:54,094:INFO:Defining folds
2025-08-06 17:38:54,094:INFO:Declaring metric variables
2025-08-06 17:38:54,115:INFO:Importing untrained model
2025-08-06 17:38:54,128:INFO:K Neighbors Regressor Imported successfully
2025-08-06 17:38:54,158:INFO:Starting cross validation
2025-08-06 17:38:54,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:47:49,098:INFO:Calculating mean and std
2025-08-06 17:47:49,099:INFO:Creating metrics dataframe
2025-08-06 17:47:49,102:INFO:Uploading results into container
2025-08-06 17:47:49,103:INFO:Uploading model into container now
2025-08-06 17:47:49,103:INFO:_master_model_container: 11
2025-08-06 17:47:49,104:INFO:_display_container: 2
2025-08-06 17:47:49,104:INFO:KNeighborsRegressor(n_jobs=-1)
2025-08-06 17:47:49,104:INFO:create_model() successfully completed......................................
2025-08-06 17:47:49,261:INFO:SubProcess create_model() end ==================================
2025-08-06 17:47:49,261:INFO:Creating metrics dataframe
2025-08-06 17:47:49,261:INFO:Initializing Decision Tree Regressor
2025-08-06 17:47:49,261:INFO:Total runtime is 16.004910147190092 minutes
2025-08-06 17:47:49,278:INFO:SubProcess create_model() called ==================================
2025-08-06 17:47:49,278:INFO:Initializing create_model()
2025-08-06 17:47:49,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:47:49,278:INFO:Checking exceptions
2025-08-06 17:47:49,278:INFO:Importing libraries
2025-08-06 17:47:49,278:INFO:Copying training dataset
2025-08-06 17:47:49,721:INFO:Defining folds
2025-08-06 17:47:49,721:INFO:Declaring metric variables
2025-08-06 17:47:49,736:INFO:Importing untrained model
2025-08-06 17:47:49,754:INFO:Decision Tree Regressor Imported successfully
2025-08-06 17:47:49,784:INFO:Starting cross validation
2025-08-06 17:47:49,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 17:48:47,361:INFO:Calculating mean and std
2025-08-06 17:48:47,361:INFO:Creating metrics dataframe
2025-08-06 17:48:47,374:INFO:Uploading results into container
2025-08-06 17:48:47,375:INFO:Uploading model into container now
2025-08-06 17:48:47,376:INFO:_master_model_container: 12
2025-08-06 17:48:47,377:INFO:_display_container: 2
2025-08-06 17:48:47,377:INFO:DecisionTreeRegressor(random_state=23)
2025-08-06 17:48:47,377:INFO:create_model() successfully completed......................................
2025-08-06 17:48:47,636:INFO:SubProcess create_model() end ==================================
2025-08-06 17:48:47,636:INFO:Creating metrics dataframe
2025-08-06 17:48:47,655:INFO:Initializing Random Forest Regressor
2025-08-06 17:48:47,655:INFO:Total runtime is 16.978133165836333 minutes
2025-08-06 17:48:47,674:INFO:SubProcess create_model() called ==================================
2025-08-06 17:48:47,674:INFO:Initializing create_model()
2025-08-06 17:48:47,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 17:48:47,674:INFO:Checking exceptions
2025-08-06 17:48:47,674:INFO:Importing libraries
2025-08-06 17:48:47,674:INFO:Copying training dataset
2025-08-06 17:48:48,254:INFO:Defining folds
2025-08-06 17:48:48,254:INFO:Declaring metric variables
2025-08-06 17:48:48,309:INFO:Importing untrained model
2025-08-06 17:48:48,317:INFO:Random Forest Regressor Imported successfully
2025-08-06 17:48:48,351:INFO:Starting cross validation
2025-08-06 17:48:48,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 18:17:19,338:INFO:Calculating mean and std
2025-08-06 18:17:19,490:INFO:Creating metrics dataframe
2025-08-06 18:17:19,628:INFO:Uploading results into container
2025-08-06 18:17:19,640:INFO:Uploading model into container now
2025-08-06 18:17:19,663:INFO:_master_model_container: 13
2025-08-06 18:17:19,663:INFO:_display_container: 2
2025-08-06 18:17:19,675:INFO:RandomForestRegressor(n_jobs=-1, random_state=23)
2025-08-06 18:17:19,675:INFO:create_model() successfully completed......................................
2025-08-06 18:17:21,094:INFO:SubProcess create_model() end ==================================
2025-08-06 18:17:21,094:INFO:Creating metrics dataframe
2025-08-06 18:17:21,114:INFO:Initializing Extra Trees Regressor
2025-08-06 18:17:21,114:INFO:Total runtime is 45.5357957402865 minutes
2025-08-06 18:17:21,126:INFO:SubProcess create_model() called ==================================
2025-08-06 18:17:21,126:INFO:Initializing create_model()
2025-08-06 18:17:21,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 18:17:21,127:INFO:Checking exceptions
2025-08-06 18:17:21,127:INFO:Importing libraries
2025-08-06 18:17:21,128:INFO:Copying training dataset
2025-08-06 18:17:21,684:INFO:Defining folds
2025-08-06 18:17:21,684:INFO:Declaring metric variables
2025-08-06 18:17:21,698:INFO:Importing untrained model
2025-08-06 18:17:21,711:INFO:Extra Trees Regressor Imported successfully
2025-08-06 18:17:21,736:INFO:Starting cross validation
2025-08-06 18:17:21,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 18:59:40,127:INFO:Calculating mean and std
2025-08-06 18:59:40,310:INFO:Creating metrics dataframe
2025-08-06 18:59:40,477:INFO:Uploading results into container
2025-08-06 18:59:40,494:INFO:Uploading model into container now
2025-08-06 18:59:40,510:INFO:_master_model_container: 14
2025-08-06 18:59:40,510:INFO:_display_container: 2
2025-08-06 18:59:40,526:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=23)
2025-08-06 18:59:40,526:INFO:create_model() successfully completed......................................
2025-08-06 18:59:41,647:INFO:SubProcess create_model() end ==================================
2025-08-06 18:59:41,647:INFO:Creating metrics dataframe
2025-08-06 18:59:41,676:INFO:Initializing AdaBoost Regressor
2025-08-06 18:59:41,676:INFO:Total runtime is 87.87849758466083 minutes
2025-08-06 18:59:41,693:INFO:SubProcess create_model() called ==================================
2025-08-06 18:59:41,693:INFO:Initializing create_model()
2025-08-06 18:59:41,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 18:59:41,693:INFO:Checking exceptions
2025-08-06 18:59:41,693:INFO:Importing libraries
2025-08-06 18:59:41,693:INFO:Copying training dataset
2025-08-06 18:59:42,378:INFO:Defining folds
2025-08-06 18:59:42,378:INFO:Declaring metric variables
2025-08-06 18:59:42,389:INFO:Importing untrained model
2025-08-06 18:59:42,402:INFO:AdaBoost Regressor Imported successfully
2025-08-06 18:59:42,431:INFO:Starting cross validation
2025-08-06 18:59:42,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 19:04:36,943:INFO:Calculating mean and std
2025-08-06 19:04:36,943:INFO:Creating metrics dataframe
2025-08-06 19:04:36,943:INFO:Uploading results into container
2025-08-06 19:04:36,960:INFO:Uploading model into container now
2025-08-06 19:04:36,960:INFO:_master_model_container: 15
2025-08-06 19:04:36,960:INFO:_display_container: 2
2025-08-06 19:04:36,960:INFO:AdaBoostRegressor(random_state=23)
2025-08-06 19:04:36,960:INFO:create_model() successfully completed......................................
2025-08-06 19:04:37,176:INFO:SubProcess create_model() end ==================================
2025-08-06 19:04:37,176:INFO:Creating metrics dataframe
2025-08-06 19:04:37,215:INFO:Initializing Gradient Boosting Regressor
2025-08-06 19:04:37,215:INFO:Total runtime is 92.80413598616917 minutes
2025-08-06 19:04:37,223:INFO:SubProcess create_model() called ==================================
2025-08-06 19:04:37,224:INFO:Initializing create_model()
2025-08-06 19:04:37,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 19:04:37,225:INFO:Checking exceptions
2025-08-06 19:04:37,225:INFO:Importing libraries
2025-08-06 19:04:37,225:INFO:Copying training dataset
2025-08-06 19:04:37,662:INFO:Defining folds
2025-08-06 19:04:37,663:INFO:Declaring metric variables
2025-08-06 19:04:37,678:INFO:Importing untrained model
2025-08-06 19:04:37,695:INFO:Gradient Boosting Regressor Imported successfully
2025-08-06 19:04:37,732:INFO:Starting cross validation
2025-08-06 19:04:37,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 19:14:16,547:INFO:Calculating mean and std
2025-08-06 19:14:16,547:INFO:Creating metrics dataframe
2025-08-06 19:14:16,562:INFO:Uploading results into container
2025-08-06 19:14:16,562:INFO:Uploading model into container now
2025-08-06 19:14:16,562:INFO:_master_model_container: 16
2025-08-06 19:14:16,562:INFO:_display_container: 2
2025-08-06 19:14:16,562:INFO:GradientBoostingRegressor(random_state=23)
2025-08-06 19:14:16,562:INFO:create_model() successfully completed......................................
2025-08-06 19:14:16,727:INFO:SubProcess create_model() end ==================================
2025-08-06 19:14:16,727:INFO:Creating metrics dataframe
2025-08-06 19:14:16,761:INFO:Initializing Extreme Gradient Boosting
2025-08-06 19:14:16,761:INFO:Total runtime is 102.4632396697998 minutes
2025-08-06 19:14:16,778:INFO:SubProcess create_model() called ==================================
2025-08-06 19:14:16,778:INFO:Initializing create_model()
2025-08-06 19:14:16,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 19:14:16,778:INFO:Checking exceptions
2025-08-06 19:14:16,778:INFO:Importing libraries
2025-08-06 19:14:16,778:INFO:Copying training dataset
2025-08-06 19:14:17,298:INFO:Defining folds
2025-08-06 19:14:17,299:INFO:Declaring metric variables
2025-08-06 19:14:17,313:INFO:Importing untrained model
2025-08-06 19:14:17,324:INFO:Extreme Gradient Boosting Imported successfully
2025-08-06 19:14:17,356:INFO:Starting cross validation
2025-08-06 19:14:17,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 19:15:28,899:INFO:Calculating mean and std
2025-08-06 19:15:28,900:INFO:Creating metrics dataframe
2025-08-06 19:15:28,900:INFO:Uploading results into container
2025-08-06 19:15:28,900:INFO:Uploading model into container now
2025-08-06 19:15:28,900:INFO:_master_model_container: 17
2025-08-06 19:15:28,900:INFO:_display_container: 2
2025-08-06 19:15:28,900:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=23, ...)
2025-08-06 19:15:28,900:INFO:create_model() successfully completed......................................
2025-08-06 19:15:29,079:INFO:SubProcess create_model() end ==================================
2025-08-06 19:15:29,079:INFO:Creating metrics dataframe
2025-08-06 19:15:30,131:INFO:Initializing Light Gradient Boosting Machine
2025-08-06 19:15:30,132:INFO:Total runtime is 103.68606975078583 minutes
2025-08-06 19:15:30,150:INFO:SubProcess create_model() called ==================================
2025-08-06 19:15:30,151:INFO:Initializing create_model()
2025-08-06 19:15:30,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 19:15:30,152:INFO:Checking exceptions
2025-08-06 19:15:30,152:INFO:Importing libraries
2025-08-06 19:15:30,152:INFO:Copying training dataset
2025-08-06 19:15:30,524:INFO:Defining folds
2025-08-06 19:15:30,524:INFO:Declaring metric variables
2025-08-06 19:15:30,534:INFO:Importing untrained model
2025-08-06 19:15:30,541:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-06 19:15:30,562:INFO:Starting cross validation
2025-08-06 19:15:30,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 19:16:35,416:INFO:Calculating mean and std
2025-08-06 19:16:35,416:INFO:Creating metrics dataframe
2025-08-06 19:16:35,416:INFO:Uploading results into container
2025-08-06 19:16:35,416:INFO:Uploading model into container now
2025-08-06 19:16:35,416:INFO:_master_model_container: 18
2025-08-06 19:16:35,416:INFO:_display_container: 2
2025-08-06 19:16:35,416:INFO:LGBMRegressor(n_jobs=-1, random_state=23)
2025-08-06 19:16:35,416:INFO:create_model() successfully completed......................................
2025-08-06 19:16:35,667:INFO:SubProcess create_model() end ==================================
2025-08-06 19:16:35,667:INFO:Creating metrics dataframe
2025-08-06 19:16:35,701:INFO:Initializing Dummy Regressor
2025-08-06 19:16:35,701:INFO:Total runtime is 104.77889950275421 minutes
2025-08-06 19:16:35,719:INFO:SubProcess create_model() called ==================================
2025-08-06 19:16:35,719:INFO:Initializing create_model()
2025-08-06 19:16:35,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C759627150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 19:16:35,720:INFO:Checking exceptions
2025-08-06 19:16:35,720:INFO:Importing libraries
2025-08-06 19:16:35,720:INFO:Copying training dataset
2025-08-06 19:16:36,352:INFO:Defining folds
2025-08-06 19:16:36,352:INFO:Declaring metric variables
2025-08-06 19:16:36,368:INFO:Importing untrained model
2025-08-06 19:16:36,390:INFO:Dummy Regressor Imported successfully
2025-08-06 19:16:36,424:INFO:Starting cross validation
2025-08-06 19:16:36,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 19:17:06,959:INFO:Calculating mean and std
2025-08-06 19:17:06,960:INFO:Creating metrics dataframe
2025-08-06 19:17:06,962:INFO:Uploading results into container
2025-08-06 19:17:06,963:INFO:Uploading model into container now
2025-08-06 19:17:06,964:INFO:_master_model_container: 19
2025-08-06 19:17:06,964:INFO:_display_container: 2
2025-08-06 19:17:06,964:INFO:DummyRegressor()
2025-08-06 19:17:06,964:INFO:create_model() successfully completed......................................
2025-08-06 19:17:07,086:INFO:SubProcess create_model() end ==================================
2025-08-06 19:17:07,087:INFO:Creating metrics dataframe
2025-08-06 19:17:07,158:WARNING:c:\Users\nobre\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-08-06 19:17:07,242:INFO:Initializing create_model()
2025-08-06 19:17:07,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C7617EB510>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=23), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 19:17:07,243:INFO:Checking exceptions
2025-08-06 19:17:07,256:INFO:Importing libraries
2025-08-06 19:17:07,256:INFO:Copying training dataset
2025-08-06 19:17:07,826:INFO:Defining folds
2025-08-06 19:17:07,826:INFO:Declaring metric variables
2025-08-06 19:17:07,826:INFO:Importing untrained model
2025-08-06 19:17:07,828:INFO:Declaring custom model
2025-08-06 19:17:07,830:INFO:Extra Trees Regressor Imported successfully
2025-08-06 19:17:07,834:INFO:Cross validation set to False
2025-08-06 19:17:07,834:INFO:Fitting Model
2025-08-06 19:22:11,461:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=23)
2025-08-06 19:22:11,461:INFO:create_model() successfully completed......................................
2025-08-06 19:22:11,753:INFO:_master_model_container: 19
2025-08-06 19:22:11,753:INFO:_display_container: 2
2025-08-06 19:22:11,754:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=23)
2025-08-06 19:22:11,754:INFO:compare_models() successfully completed......................................
2025-08-06 19:23:31,225:INFO:PyCaret RegressionExperiment
2025-08-06 19:23:31,225:INFO:Logging name: reg-default-name
2025-08-06 19:23:31,225:INFO:ML Usecase: MLUsecase.REGRESSION
2025-08-06 19:23:31,225:INFO:version 3.3.2
2025-08-06 19:23:31,225:INFO:Initializing setup()
2025-08-06 19:23:31,225:INFO:self.USI: 7342
2025-08-06 19:23:31,225:INFO:self._variable_keys: {'y_train', 'X_train', 'fold_shuffle_param', 'data', 'memory', 'fold_groups_param', 'exp_name_log', 'idx', 'X_test', 'y_test', 'y', '_ml_usecase', 'gpu_n_jobs_param', 'html_param', 'seed', 'X', 'logging_param', 'exp_id', 'USI', 'gpu_param', 'transform_target_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'pipeline'}
2025-08-06 19:23:31,225:INFO:Checking environment
2025-08-06 19:23:31,225:INFO:python_version: 3.11.7
2025-08-06 19:23:31,225:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-08-06 19:23:31,225:INFO:machine: AMD64
2025-08-06 19:23:31,225:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-06 19:23:31,225:INFO:Memory: svmem(total=8474312704, available=675049472, percent=92.0, used=7799263232, free=675049472)
2025-08-06 19:23:31,225:INFO:Physical Core: 2
2025-08-06 19:23:31,225:INFO:Logical Core: 4
2025-08-06 19:23:31,225:INFO:Checking libraries
2025-08-06 19:23:31,225:INFO:System:
2025-08-06 19:23:31,225:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-08-06 19:23:31,225:INFO:executable: c:\Users\nobre\anaconda3\python.exe
2025-08-06 19:23:31,225:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-06 19:23:31,225:INFO:PyCaret required dependencies:
2025-08-06 19:23:31,225:INFO:                 pip: 23.3.1
2025-08-06 19:23:31,225:INFO:          setuptools: 68.2.2
2025-08-06 19:23:31,225:INFO:             pycaret: 3.3.2
2025-08-06 19:23:31,225:INFO:             IPython: 8.20.0
2025-08-06 19:23:31,225:INFO:          ipywidgets: 7.6.5
2025-08-06 19:23:31,225:INFO:                tqdm: 4.65.0
2025-08-06 19:23:31,225:INFO:               numpy: 1.26.4
2025-08-06 19:23:31,225:INFO:              pandas: 2.1.4
2025-08-06 19:23:31,225:INFO:              jinja2: 3.1.3
2025-08-06 19:23:31,225:INFO:               scipy: 1.11.4
2025-08-06 19:23:31,225:INFO:              joblib: 1.2.0
2025-08-06 19:23:31,225:INFO:             sklearn: 1.4.2
2025-08-06 19:23:31,225:INFO:                pyod: 2.0.2
2025-08-06 19:23:31,225:INFO:            imblearn: 0.12.4
2025-08-06 19:23:31,225:INFO:   category_encoders: 2.6.4
2025-08-06 19:23:31,225:INFO:            lightgbm: 4.4.0
2025-08-06 19:23:31,225:INFO:               numba: 0.59.0
2025-08-06 19:23:31,225:INFO:            requests: 2.32.3
2025-08-06 19:23:31,225:INFO:          matplotlib: 3.7.5
2025-08-06 19:23:31,225:INFO:          scikitplot: 0.3.7
2025-08-06 19:23:31,225:INFO:         yellowbrick: 1.5
2025-08-06 19:23:31,225:INFO:              plotly: 5.24.1
2025-08-06 19:23:31,225:INFO:    plotly-resampler: Not installed
2025-08-06 19:23:31,225:INFO:             kaleido: 0.2.1
2025-08-06 19:23:31,225:INFO:           schemdraw: 0.15
2025-08-06 19:23:31,225:INFO:         statsmodels: 0.14.0
2025-08-06 19:23:31,225:INFO:              sktime: 0.26.0
2025-08-06 19:23:31,225:INFO:               tbats: 1.1.3
2025-08-06 19:23:31,240:INFO:            pmdarima: 2.0.4
2025-08-06 19:23:31,240:INFO:              psutil: 5.9.0
2025-08-06 19:23:31,240:INFO:          markupsafe: 2.1.3
2025-08-06 19:23:31,240:INFO:             pickle5: Not installed
2025-08-06 19:23:31,241:INFO:         cloudpickle: 2.2.1
2025-08-06 19:23:31,242:INFO:         deprecation: 2.1.0
2025-08-06 19:23:31,242:INFO:              xxhash: 3.5.0
2025-08-06 19:23:31,242:INFO:           wurlitzer: 3.1.1
2025-08-06 19:23:31,242:INFO:PyCaret optional dependencies:
2025-08-06 19:23:31,242:INFO:                shap: Not installed
2025-08-06 19:23:31,242:INFO:           interpret: Not installed
2025-08-06 19:23:31,242:INFO:                umap: Not installed
2025-08-06 19:23:31,242:INFO:     ydata_profiling: 4.12.0
2025-08-06 19:23:31,242:INFO:  explainerdashboard: Not installed
2025-08-06 19:23:31,242:INFO:             autoviz: Not installed
2025-08-06 19:23:31,242:INFO:           fairlearn: Not installed
2025-08-06 19:23:31,242:INFO:          deepchecks: Not installed
2025-08-06 19:23:31,242:INFO:             xgboost: 2.1.0
2025-08-06 19:23:31,242:INFO:            catboost: Not installed
2025-08-06 19:23:31,242:INFO:              kmodes: Not installed
2025-08-06 19:23:31,242:INFO:             mlxtend: Not installed
2025-08-06 19:23:31,242:INFO:       statsforecast: Not installed
2025-08-06 19:23:31,242:INFO:        tune_sklearn: Not installed
2025-08-06 19:23:31,242:INFO:                 ray: Not installed
2025-08-06 19:23:31,242:INFO:            hyperopt: Not installed
2025-08-06 19:23:31,242:INFO:              optuna: Not installed
2025-08-06 19:23:31,242:INFO:               skopt: Not installed
2025-08-06 19:23:31,242:INFO:              mlflow: Not installed
2025-08-06 19:23:31,242:INFO:              gradio: Not installed
2025-08-06 19:23:31,242:INFO:             fastapi: Not installed
2025-08-06 19:23:31,242:INFO:             uvicorn: Not installed
2025-08-06 19:23:31,242:INFO:              m2cgen: Not installed
2025-08-06 19:23:31,242:INFO:           evidently: Not installed
2025-08-06 19:23:31,242:INFO:               fugue: Not installed
2025-08-06 19:23:31,242:INFO:           streamlit: 1.30.0
2025-08-06 19:23:31,242:INFO:             prophet: Not installed
2025-08-06 19:23:31,242:INFO:None
2025-08-06 19:23:31,242:INFO:Set up data.
2025-08-06 19:23:31,758:INFO:Set up folding strategy.
2025-08-06 19:23:31,758:INFO:Set up train/test split.
2025-08-06 19:23:32,008:INFO:Set up index.
2025-08-06 19:23:32,041:INFO:Assigning column types.
2025-08-06 19:23:32,373:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-06 19:23:32,374:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,376:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,875:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:32,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:32,875:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,892:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:23:32,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,257:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,323:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:33,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:33,323:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-08-06 19:23:33,323:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,377:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,841:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:33,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:33,857:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:23:33,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:23:34,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:34,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:34,328:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:34,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:34,344:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-08-06 19:23:34,359:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:23:34,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:34,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:34,742:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:34,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:34,745:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:23:35,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:35,187:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:35,187:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:35,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:35,193:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-08-06 19:23:35,540:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:35,595:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:35,595:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:35,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:35,941:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:36,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:23:36,010:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:36,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:36,015:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-06 19:23:36,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:36,957:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:36,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:37,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:23:38,143:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:38,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:38,193:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-08-06 19:23:38,941:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:38,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:39,821:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:23:39,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:23:39,837:INFO:Preparing preprocessing pipeline...
2025-08-06 19:23:39,837:INFO:Set up simple imputation.
2025-08-06 19:23:40,140:INFO:Set up encoding of categorical features.
2025-08-06 19:23:41,141:WARNING:c:\Users\nobre\anaconda3\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['posse_de_veiculo' 'posse_de_imovel']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-08-06 19:23:46,043:WARNING:c:\Users\nobre\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-08-06 19:23:46,059:INFO:Finished creating preprocessing pipeline.
2025-08-06 19:23:46,907:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nobre\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sexo', 'posse_de_veiculo',
                                             'posse_de_imovel', 'qtd_filhos',
                                             'idade', 'qt_pessoas_residencia',
                                             'renda', 'mau'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-08-06 19:23:46,907:INFO:Creating final display dataframe.
2025-08-06 19:23:57,939:WARNING:c:\Users\nobre\anaconda3\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['posse_de_veiculo' 'posse_de_imovel']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-08-06 19:24:02,678:INFO:Setup _display_container:                     Description             Value
0                    Session id                23
1                        Target     tempo_emprego
2                   Target type        Regression
3           Original data shape      (624043, 13)
4        Transformed data shape      (624043, 28)
5   Transformed train set shape      (436830, 28)
6    Transformed test set shape      (187213, 28)
7              Numeric features                 8
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              7342
2025-08-06 19:24:04,195:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:24:04,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:24:05,018:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:24:05,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:24:05,022:INFO:setup() successfully completed in 33.83s...............
2025-08-06 19:25:39,366:INFO:PyCaret RegressionExperiment
2025-08-06 19:25:39,366:INFO:Logging name: reg-default-name
2025-08-06 19:25:39,366:INFO:ML Usecase: MLUsecase.REGRESSION
2025-08-06 19:25:39,366:INFO:version 3.3.2
2025-08-06 19:25:39,366:INFO:Initializing setup()
2025-08-06 19:25:39,366:INFO:self.USI: 6f89
2025-08-06 19:25:39,366:INFO:self._variable_keys: {'y_train', 'X_train', 'fold_shuffle_param', 'data', 'memory', 'fold_groups_param', 'exp_name_log', 'idx', 'X_test', 'y_test', 'y', '_ml_usecase', 'gpu_n_jobs_param', 'html_param', 'seed', 'X', 'logging_param', 'exp_id', 'USI', 'gpu_param', 'transform_target_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_generator', '_available_plots', 'pipeline'}
2025-08-06 19:25:39,366:INFO:Checking environment
2025-08-06 19:25:39,366:INFO:python_version: 3.11.7
2025-08-06 19:25:39,366:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-08-06 19:25:39,366:INFO:machine: AMD64
2025-08-06 19:25:39,366:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-06 19:25:39,366:INFO:Memory: svmem(total=8474312704, available=1165135872, percent=86.3, used=7309176832, free=1165135872)
2025-08-06 19:25:39,366:INFO:Physical Core: 2
2025-08-06 19:25:39,366:INFO:Logical Core: 4
2025-08-06 19:25:39,366:INFO:Checking libraries
2025-08-06 19:25:39,366:INFO:System:
2025-08-06 19:25:39,366:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-08-06 19:25:39,366:INFO:executable: c:\Users\nobre\anaconda3\python.exe
2025-08-06 19:25:39,366:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-06 19:25:39,366:INFO:PyCaret required dependencies:
2025-08-06 19:25:39,366:INFO:                 pip: 23.3.1
2025-08-06 19:25:39,366:INFO:          setuptools: 68.2.2
2025-08-06 19:25:39,366:INFO:             pycaret: 3.3.2
2025-08-06 19:25:39,366:INFO:             IPython: 8.20.0
2025-08-06 19:25:39,366:INFO:          ipywidgets: 7.6.5
2025-08-06 19:25:39,366:INFO:                tqdm: 4.65.0
2025-08-06 19:25:39,366:INFO:               numpy: 1.26.4
2025-08-06 19:25:39,366:INFO:              pandas: 2.1.4
2025-08-06 19:25:39,366:INFO:              jinja2: 3.1.3
2025-08-06 19:25:39,366:INFO:               scipy: 1.11.4
2025-08-06 19:25:39,366:INFO:              joblib: 1.2.0
2025-08-06 19:25:39,366:INFO:             sklearn: 1.4.2
2025-08-06 19:25:39,366:INFO:                pyod: 2.0.2
2025-08-06 19:25:39,366:INFO:            imblearn: 0.12.4
2025-08-06 19:25:39,382:INFO:   category_encoders: 2.6.4
2025-08-06 19:25:39,382:INFO:            lightgbm: 4.4.0
2025-08-06 19:25:39,382:INFO:               numba: 0.59.0
2025-08-06 19:25:39,382:INFO:            requests: 2.32.3
2025-08-06 19:25:39,382:INFO:          matplotlib: 3.7.5
2025-08-06 19:25:39,382:INFO:          scikitplot: 0.3.7
2025-08-06 19:25:39,383:INFO:         yellowbrick: 1.5
2025-08-06 19:25:39,383:INFO:              plotly: 5.24.1
2025-08-06 19:25:39,383:INFO:    plotly-resampler: Not installed
2025-08-06 19:25:39,383:INFO:             kaleido: 0.2.1
2025-08-06 19:25:39,383:INFO:           schemdraw: 0.15
2025-08-06 19:25:39,383:INFO:         statsmodels: 0.14.0
2025-08-06 19:25:39,383:INFO:              sktime: 0.26.0
2025-08-06 19:25:39,383:INFO:               tbats: 1.1.3
2025-08-06 19:25:39,383:INFO:            pmdarima: 2.0.4
2025-08-06 19:25:39,383:INFO:              psutil: 5.9.0
2025-08-06 19:25:39,383:INFO:          markupsafe: 2.1.3
2025-08-06 19:25:39,383:INFO:             pickle5: Not installed
2025-08-06 19:25:39,383:INFO:         cloudpickle: 2.2.1
2025-08-06 19:25:39,383:INFO:         deprecation: 2.1.0
2025-08-06 19:25:39,383:INFO:              xxhash: 3.5.0
2025-08-06 19:25:39,384:INFO:           wurlitzer: 3.1.1
2025-08-06 19:25:39,384:INFO:PyCaret optional dependencies:
2025-08-06 19:25:39,384:INFO:                shap: Not installed
2025-08-06 19:25:39,384:INFO:           interpret: Not installed
2025-08-06 19:25:39,384:INFO:                umap: Not installed
2025-08-06 19:25:39,384:INFO:     ydata_profiling: 4.12.0
2025-08-06 19:25:39,384:INFO:  explainerdashboard: Not installed
2025-08-06 19:25:39,384:INFO:             autoviz: Not installed
2025-08-06 19:25:39,385:INFO:           fairlearn: Not installed
2025-08-06 19:25:39,385:INFO:          deepchecks: Not installed
2025-08-06 19:25:39,385:INFO:             xgboost: 2.1.0
2025-08-06 19:25:39,385:INFO:            catboost: Not installed
2025-08-06 19:25:39,385:INFO:              kmodes: Not installed
2025-08-06 19:25:39,385:INFO:             mlxtend: Not installed
2025-08-06 19:25:39,385:INFO:       statsforecast: Not installed
2025-08-06 19:25:39,385:INFO:        tune_sklearn: Not installed
2025-08-06 19:25:39,385:INFO:                 ray: Not installed
2025-08-06 19:25:39,385:INFO:            hyperopt: Not installed
2025-08-06 19:25:39,386:INFO:              optuna: Not installed
2025-08-06 19:25:39,386:INFO:               skopt: Not installed
2025-08-06 19:25:39,386:INFO:              mlflow: Not installed
2025-08-06 19:25:39,386:INFO:              gradio: Not installed
2025-08-06 19:25:39,386:INFO:             fastapi: Not installed
2025-08-06 19:25:39,386:INFO:             uvicorn: Not installed
2025-08-06 19:25:39,386:INFO:              m2cgen: Not installed
2025-08-06 19:25:39,386:INFO:           evidently: Not installed
2025-08-06 19:25:39,386:INFO:               fugue: Not installed
2025-08-06 19:25:39,387:INFO:           streamlit: 1.30.0
2025-08-06 19:25:39,387:INFO:             prophet: Not installed
2025-08-06 19:25:39,387:INFO:None
2025-08-06 19:25:39,387:INFO:Set up data.
2025-08-06 19:25:39,936:INFO:Set up folding strategy.
2025-08-06 19:25:39,936:INFO:Set up train/test split.
2025-08-06 19:25:40,116:INFO:Set up index.
2025-08-06 19:25:40,158:INFO:Assigning column types.
2025-08-06 19:25:40,319:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-06 19:25:40,319:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,319:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,822:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:40,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:40,822:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:25:40,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,195:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:41,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:41,195:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-08-06 19:25:41,195:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,219:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,551:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,551:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:41,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:41,567:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:41,945:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:41,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:41,951:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-08-06 19:25:41,951:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:25:42,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:42,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:42,390:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:42,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:42,410:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-06 19:25:42,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:42,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:42,820:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:42,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:42,823:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-08-06 19:25:43,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:43,193:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:43,209:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:43,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:43,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:43,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-06 19:25:43,565:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:43,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:43,570:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-06 19:25:43,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:43,914:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:43,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:44,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-06 19:25:44,284:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:44,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:44,299:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-08-06 19:25:44,646:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:44,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:45,086:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:25:45,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:25:45,101:INFO:Preparing preprocessing pipeline...
2025-08-06 19:25:45,101:INFO:Set up simple imputation.
2025-08-06 19:25:45,318:INFO:Set up encoding of ordinal features.
2025-08-06 19:25:45,420:INFO:Set up encoding of categorical features.
2025-08-06 19:25:47,651:INFO:Finished creating preprocessing pipeline.
2025-08-06 19:25:47,718:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nobre\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sexo', 'qtd_filhos', 'idade',
                                             'qt_pessoas_residencia', 'renda',
                                             'mau'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['posse_de_veiculo',
                                             'posse_de_imovel', 'tipo_renda',
                                             'educacao', 'estado...
S      1
NaN   -1
dtype: int64},
                                                                        {'col': 'posse_de_imovel',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': N      0
S      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-08-06 19:25:47,718:INFO:Creating final display dataframe.
2025-08-06 19:26:09,998:INFO:Setup _display_container:                     Description             Value
0                    Session id                23
1                        Target     tempo_emprego
2                   Target type        Regression
3           Original data shape      (624043, 13)
4        Transformed data shape      (624043, 30)
5   Transformed train set shape      (436830, 30)
6    Transformed test set shape      (187213, 30)
7              Numeric features                 6
8          Categorical features                 6
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              6f89
2025-08-06 19:26:10,437:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:26:10,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:26:10,837:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-06 19:26:10,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-06 19:26:10,841:INFO:setup() successfully completed in 31.48s...............
2025-08-06 19:26:49,892:INFO:Initializing create_model()
2025-08-06 19:26:49,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C70068EF50>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-06 19:26:49,893:INFO:Checking exceptions
2025-08-06 19:26:49,940:INFO:Importing libraries
2025-08-06 19:26:49,940:INFO:Copying training dataset
2025-08-06 19:26:50,818:INFO:Defining folds
2025-08-06 19:26:50,818:INFO:Declaring metric variables
2025-08-06 19:26:50,842:INFO:Importing untrained model
2025-08-06 19:26:50,858:INFO:Decision Tree Regressor Imported successfully
2025-08-06 19:26:50,886:INFO:Starting cross validation
2025-08-06 19:26:50,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-06 19:28:29,568:INFO:Calculating mean and std
2025-08-06 19:28:30,029:INFO:Creating metrics dataframe
2025-08-06 19:28:30,083:INFO:Finalizing model
2025-08-06 19:28:40,008:INFO:Uploading results into container
2025-08-06 19:28:40,009:INFO:Uploading model into container now
2025-08-06 19:28:40,066:INFO:_master_model_container: 1
2025-08-06 19:28:40,067:INFO:_display_container: 2
2025-08-06 19:28:40,068:INFO:DecisionTreeRegressor(random_state=23)
2025-08-06 19:28:40,069:INFO:create_model() successfully completed......................................
2025-08-06 19:29:37,700:INFO:Initializing tune_model()
2025-08-06 19:29:37,700:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C70068EF50>, estimator=DecisionTreeRegressor(random_state=23), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-08-06 19:29:37,700:INFO:Checking exceptions
2025-08-06 19:29:38,061:INFO:Copying training dataset
2025-08-06 19:29:38,465:INFO:Checking base model
2025-08-06 19:29:38,465:INFO:Base model : Decision Tree Regressor
2025-08-06 19:29:38,490:INFO:Declaring metric variables
2025-08-06 19:29:38,503:INFO:Defining Hyperparameters
2025-08-06 19:29:38,883:INFO:Tuning with n_jobs=-1
2025-08-06 19:29:38,883:INFO:Initializing RandomizedSearchCV
2025-08-08 20:18:08,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 20:18:08,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 20:18:08,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 20:18:08,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 20:18:40,258:INFO:PyCaret ClassificationExperiment
2025-08-08 20:18:40,258:INFO:Logging name: clf-default-name
2025-08-08 20:18:40,258:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-08 20:18:40,267:INFO:version 3.3.2
2025-08-08 20:18:40,268:INFO:Initializing setup()
2025-08-08 20:18:40,268:INFO:self.USI: 5120
2025-08-08 20:18:40,268:INFO:self._variable_keys: {'_ml_usecase', 'target_param', 'X_test', 'exp_name_log', '_available_plots', 'pipeline', 'X', 'y_test', 'memory', 'gpu_param', 'y', 'n_jobs_param', 'USI', 'fold_groups_param', 'fix_imbalance', 'idx', 'logging_param', 'X_train', 'seed', 'gpu_n_jobs_param', 'log_plots_param', 'y_train', 'fold_generator', 'exp_id', 'data', 'fold_shuffle_param', 'html_param', 'is_multiclass'}
2025-08-08 20:18:40,268:INFO:Checking environment
2025-08-08 20:18:40,269:INFO:python_version: 3.11.7
2025-08-08 20:18:40,269:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-08-08 20:18:40,269:INFO:machine: AMD64
2025-08-08 20:18:40,269:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-08 20:18:40,270:INFO:Memory: svmem(total=8474312704, available=1258549248, percent=85.1, used=7215763456, free=1258549248)
2025-08-08 20:18:40,272:INFO:Physical Core: 2
2025-08-08 20:18:40,272:INFO:Logical Core: 4
2025-08-08 20:18:40,272:INFO:Checking libraries
2025-08-08 20:18:40,272:INFO:System:
2025-08-08 20:18:40,272:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-08-08 20:18:40,272:INFO:executable: c:\Users\nobre\anaconda3\python.exe
2025-08-08 20:18:40,272:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-08 20:18:40,272:INFO:PyCaret required dependencies:
2025-08-08 20:18:43,350:INFO:                 pip: 23.3.1
2025-08-08 20:18:43,350:INFO:          setuptools: 68.2.2
2025-08-08 20:18:43,350:INFO:             pycaret: 3.3.2
2025-08-08 20:18:43,350:INFO:             IPython: 8.20.0
2025-08-08 20:18:43,350:INFO:          ipywidgets: 7.6.5
2025-08-08 20:18:43,350:INFO:                tqdm: 4.65.0
2025-08-08 20:18:43,350:INFO:               numpy: 1.26.4
2025-08-08 20:18:43,350:INFO:              pandas: 2.1.4
2025-08-08 20:18:43,350:INFO:              jinja2: 3.1.3
2025-08-08 20:18:43,350:INFO:               scipy: 1.11.4
2025-08-08 20:18:43,350:INFO:              joblib: 1.2.0
2025-08-08 20:18:43,350:INFO:             sklearn: 1.4.2
2025-08-08 20:18:43,350:INFO:                pyod: 2.0.2
2025-08-08 20:18:43,350:INFO:            imblearn: 0.12.4
2025-08-08 20:18:43,350:INFO:   category_encoders: 2.6.4
2025-08-08 20:18:43,350:INFO:            lightgbm: 4.4.0
2025-08-08 20:18:43,350:INFO:               numba: 0.59.0
2025-08-08 20:18:43,350:INFO:            requests: 2.32.3
2025-08-08 20:18:43,350:INFO:          matplotlib: 3.7.5
2025-08-08 20:18:43,350:INFO:          scikitplot: 0.3.7
2025-08-08 20:18:43,350:INFO:         yellowbrick: 1.5
2025-08-08 20:18:43,350:INFO:              plotly: 5.24.1
2025-08-08 20:18:43,350:INFO:    plotly-resampler: Not installed
2025-08-08 20:18:43,350:INFO:             kaleido: 0.2.1
2025-08-08 20:18:43,350:INFO:           schemdraw: 0.15
2025-08-08 20:18:43,350:INFO:         statsmodels: 0.14.0
2025-08-08 20:18:43,350:INFO:              sktime: 0.26.0
2025-08-08 20:18:43,350:INFO:               tbats: 1.1.3
2025-08-08 20:18:43,350:INFO:            pmdarima: 2.0.4
2025-08-08 20:18:43,350:INFO:              psutil: 5.9.0
2025-08-08 20:18:43,350:INFO:          markupsafe: 2.1.3
2025-08-08 20:18:43,350:INFO:             pickle5: Not installed
2025-08-08 20:18:43,350:INFO:         cloudpickle: 2.2.1
2025-08-08 20:18:43,350:INFO:         deprecation: 2.1.0
2025-08-08 20:18:43,350:INFO:              xxhash: 3.5.0
2025-08-08 20:18:43,350:INFO:           wurlitzer: 3.1.1
2025-08-08 20:18:43,350:INFO:PyCaret optional dependencies:
2025-08-08 20:18:43,599:INFO:                shap: Not installed
2025-08-08 20:18:43,599:INFO:           interpret: Not installed
2025-08-08 20:18:43,599:INFO:                umap: Not installed
2025-08-08 20:18:43,599:INFO:     ydata_profiling: 4.12.0
2025-08-08 20:18:43,614:INFO:  explainerdashboard: Not installed
2025-08-08 20:18:43,616:INFO:             autoviz: Not installed
2025-08-08 20:18:43,616:INFO:           fairlearn: Not installed
2025-08-08 20:18:43,616:INFO:          deepchecks: Not installed
2025-08-08 20:18:43,616:INFO:             xgboost: 2.1.0
2025-08-08 20:18:43,616:INFO:            catboost: Not installed
2025-08-08 20:18:43,616:INFO:              kmodes: Not installed
2025-08-08 20:18:43,616:INFO:             mlxtend: Not installed
2025-08-08 20:18:43,616:INFO:       statsforecast: Not installed
2025-08-08 20:18:43,616:INFO:        tune_sklearn: Not installed
2025-08-08 20:18:43,616:INFO:                 ray: Not installed
2025-08-08 20:18:43,616:INFO:            hyperopt: Not installed
2025-08-08 20:18:43,616:INFO:              optuna: Not installed
2025-08-08 20:18:43,616:INFO:               skopt: Not installed
2025-08-08 20:18:43,616:INFO:              mlflow: Not installed
2025-08-08 20:18:43,616:INFO:              gradio: Not installed
2025-08-08 20:18:43,616:INFO:             fastapi: Not installed
2025-08-08 20:18:43,616:INFO:             uvicorn: Not installed
2025-08-08 20:18:43,616:INFO:              m2cgen: Not installed
2025-08-08 20:18:43,616:INFO:           evidently: Not installed
2025-08-08 20:18:43,616:INFO:               fugue: Not installed
2025-08-08 20:18:43,616:INFO:           streamlit: 1.30.0
2025-08-08 20:18:43,616:INFO:             prophet: Not installed
2025-08-08 20:18:43,616:INFO:None
2025-08-08 20:18:43,616:INFO:Set up data.
2025-08-08 20:18:44,305:INFO:Set up folding strategy.
2025-08-08 20:18:44,305:INFO:Set up train/test split.
2025-08-08 20:18:44,767:INFO:Set up index.
2025-08-08 20:18:44,808:INFO:Assigning column types.
2025-08-08 20:18:44,950:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-08 20:18:45,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 20:18:45,051:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 20:18:45,152:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:18:45,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:18:45,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 20:18:45,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 20:18:45,266:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:18:45,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:18:45,283:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-08 20:18:45,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 20:18:45,384:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:18:45,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:18:45,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 20:18:45,518:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:18:45,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:18:45,536:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-08 20:18:45,651:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:18:45,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:18:45,783:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:18:45,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:18:45,799:INFO:Preparing preprocessing pipeline...
2025-08-08 20:18:45,814:INFO:Set up simple imputation.
2025-08-08 20:18:46,015:INFO:Set up encoding of ordinal features.
2025-08-08 20:18:46,145:INFO:Set up encoding of categorical features.
2025-08-08 20:18:53,044:INFO:Finished creating preprocessing pipeline.
2025-08-08 20:18:53,096:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nobre\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-08-08 20:18:53,096:INFO:Creating final display dataframe.
2025-08-08 20:19:27,544:INFO:Setup _display_container:                     Description             Value
0                    Session id              6271
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (712500, 13)
4        Transformed data shape      (712500, 30)
5   Transformed train set shape      (498749, 30)
6    Transformed test set shape      (213751, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5120
2025-08-08 20:19:27,788:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:19:27,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:19:27,886:INFO:Soft dependency imported: xgboost: 2.1.0
2025-08-08 20:19:27,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 20:19:27,892:INFO:setup() successfully completed in 47.73s...............
2025-08-08 20:20:10,826:INFO:Initializing create_model()
2025-08-08 20:20:10,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 20:20:10,826:INFO:Checking exceptions
2025-08-08 20:20:10,892:INFO:Importing libraries
2025-08-08 20:20:10,892:INFO:Copying training dataset
2025-08-08 20:20:11,885:INFO:Defining folds
2025-08-08 20:20:11,886:INFO:Declaring metric variables
2025-08-08 20:20:11,897:INFO:Importing untrained model
2025-08-08 20:20:11,909:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-08 20:20:11,939:INFO:Starting cross validation
2025-08-08 20:20:11,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 20:21:52,000:INFO:Calculating mean and std
2025-08-08 20:21:52,130:INFO:Creating metrics dataframe
2025-08-08 20:21:52,342:INFO:Finalizing model
2025-08-08 20:22:02,508:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-08-08 20:22:02,525:INFO:[LightGBM] [Info] Number of positive: 39043, number of negative: 459706
2025-08-08 20:22:02,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,219551 seconds.
2025-08-08 20:22:02,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-08-08 20:22:02,825:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-08-08 20:22:02,858:INFO:[LightGBM] [Info] Total Bins 624
2025-08-08 20:22:02,858:INFO:[LightGBM] [Info] Number of data points in the train set: 498749, number of used features: 29
2025-08-08 20:22:02,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,078282 -> initscore=-2,465924
2025-08-08 20:22:02,875:INFO:[LightGBM] [Info] Start training from score -2,465924
2025-08-08 20:22:06,135:INFO:Uploading results into container
2025-08-08 20:22:06,136:INFO:Uploading model into container now
2025-08-08 20:22:06,349:INFO:_master_model_container: 1
2025-08-08 20:22:06,349:INFO:_display_container: 2
2025-08-08 20:22:06,349:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6271, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-08 20:22:06,349:INFO:create_model() successfully completed......................................
2025-08-08 20:22:21,031:INFO:Initializing tune_model()
2025-08-08 20:22:21,031:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6271, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-08-08 20:22:21,031:INFO:Checking exceptions
2025-08-08 20:22:21,488:INFO:Copying training dataset
2025-08-08 20:22:22,061:INFO:Checking base model
2025-08-08 20:22:22,062:INFO:Base model : Light Gradient Boosting Machine
2025-08-08 20:22:22,079:INFO:Declaring metric variables
2025-08-08 20:22:22,089:INFO:Defining Hyperparameters
2025-08-08 20:22:22,725:INFO:Tuning with n_jobs=-1
2025-08-08 20:22:22,725:INFO:Initializing RandomizedSearchCV
2025-08-08 20:45:21,784:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 6, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 71, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 1.0}
2025-08-08 20:45:21,809:INFO:Hyperparameter search completed
2025-08-08 20:45:21,809:INFO:SubProcess create_model() called ==================================
2025-08-08 20:45:21,817:INFO:Initializing create_model()
2025-08-08 20:45:21,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6271, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002533D53D4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.4, 'num_leaves': 6, 'n_estimators': 100, 'min_split_gain': 0.8, 'min_child_samples': 71, 'learning_rate': 0.3, 'feature_fraction': 0.9, 'bagging_freq': 2, 'bagging_fraction': 1.0})
2025-08-08 20:45:21,818:INFO:Checking exceptions
2025-08-08 20:45:21,820:INFO:Importing libraries
2025-08-08 20:45:21,820:INFO:Copying training dataset
2025-08-08 20:45:24,253:INFO:Defining folds
2025-08-08 20:45:24,254:INFO:Declaring metric variables
2025-08-08 20:45:24,294:INFO:Importing untrained model
2025-08-08 20:45:24,294:INFO:Declaring custom model
2025-08-08 20:45:24,315:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-08 20:45:24,365:INFO:Starting cross validation
2025-08-08 20:45:24,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 20:46:25,317:INFO:Calculating mean and std
2025-08-08 20:46:25,319:INFO:Creating metrics dataframe
2025-08-08 20:46:25,347:INFO:Finalizing model
2025-08-08 20:46:32,839:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-08 20:46:32,839:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-08 20:46:32,839:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-08 20:46:33,305:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-08-08 20:46:33,321:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-08 20:46:33,321:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-08 20:46:33,321:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-08 20:46:33,321:INFO:[LightGBM] [Info] Number of positive: 39043, number of negative: 459706
2025-08-08 20:46:33,485:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,101876 seconds.
2025-08-08 20:46:33,486:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-08-08 20:46:33,488:INFO:[LightGBM] [Info] Total Bins 624
2025-08-08 20:46:33,488:INFO:[LightGBM] [Info] Number of data points in the train set: 498749, number of used features: 29
2025-08-08 20:46:33,510:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,078282 -> initscore=-2,465924
2025-08-08 20:46:33,511:INFO:[LightGBM] [Info] Start training from score -2,465924
2025-08-08 20:46:34,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:34,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:34,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:34,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:34,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:34,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:34,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,256:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,316:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,436:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,478:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,558:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:35,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:36,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:36,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:36,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:36,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:36,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-08 20:46:36,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-08 20:46:36,109:INFO:Uploading results into container
2025-08-08 20:46:36,113:INFO:Uploading model into container now
2025-08-08 20:46:36,116:INFO:_master_model_container: 2
2025-08-08 20:46:36,116:INFO:_display_container: 3
2025-08-08 20:46:36,118:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-08 20:46:36,118:INFO:create_model() successfully completed......................................
2025-08-08 20:46:36,734:INFO:SubProcess create_model() end ==================================
2025-08-08 20:46:36,734:INFO:choose_better activated
2025-08-08 20:46:36,749:INFO:SubProcess create_model() called ==================================
2025-08-08 20:46:36,749:INFO:Initializing create_model()
2025-08-08 20:46:36,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6271, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 20:46:36,750:INFO:Checking exceptions
2025-08-08 20:46:36,751:INFO:Importing libraries
2025-08-08 20:46:36,752:INFO:Copying training dataset
2025-08-08 20:46:37,221:INFO:Defining folds
2025-08-08 20:46:37,221:INFO:Declaring metric variables
2025-08-08 20:46:37,221:INFO:Importing untrained model
2025-08-08 20:46:37,221:INFO:Declaring custom model
2025-08-08 20:46:37,222:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-08 20:46:37,222:INFO:Starting cross validation
2025-08-08 20:46:37,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 20:47:50,370:INFO:Calculating mean and std
2025-08-08 20:47:50,371:INFO:Creating metrics dataframe
2025-08-08 20:47:50,375:INFO:Finalizing model
2025-08-08 20:47:57,038:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-08-08 20:47:57,056:INFO:[LightGBM] [Info] Number of positive: 39043, number of negative: 459706
2025-08-08 20:47:57,226:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,074919 seconds.
2025-08-08 20:47:57,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-08-08 20:47:57,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-08-08 20:47:57,227:INFO:[LightGBM] [Info] Total Bins 624
2025-08-08 20:47:57,228:INFO:[LightGBM] [Info] Number of data points in the train set: 498749, number of used features: 29
2025-08-08 20:47:57,232:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,078282 -> initscore=-2,465924
2025-08-08 20:47:57,235:INFO:[LightGBM] [Info] Start training from score -2,465924
2025-08-08 20:48:01,299:INFO:Uploading results into container
2025-08-08 20:48:01,300:INFO:Uploading model into container now
2025-08-08 20:48:01,301:INFO:_master_model_container: 3
2025-08-08 20:48:01,301:INFO:_display_container: 4
2025-08-08 20:48:01,303:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6271, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-08 20:48:01,303:INFO:create_model() successfully completed......................................
2025-08-08 20:48:01,578:INFO:SubProcess create_model() end ==================================
2025-08-08 20:48:01,579:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6271, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.922
2025-08-08 20:48:01,580:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9222
2025-08-08 20:48:01,581:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-08-08 20:48:01,581:INFO:choose_better completed
2025-08-08 20:48:01,601:INFO:_master_model_container: 3
2025-08-08 20:48:01,601:INFO:_display_container: 3
2025-08-08 20:48:01,603:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-08 20:48:01,603:INFO:tune_model() successfully completed......................................
2025-08-09 13:22:29,702:INFO:Initializing plot_model()
2025-08-09 13:22:29,702:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-09 13:22:29,702:INFO:Checking exceptions
2025-08-09 13:22:30,075:INFO:Preloading libraries
2025-08-09 13:22:30,142:INFO:Copying training dataset
2025-08-09 13:22:30,143:INFO:Plot type: feature
2025-08-09 13:22:30,144:WARNING:No coef_ found. Trying feature_importances_
2025-08-09 13:22:33,306:INFO:Visual Rendered Successfully
2025-08-09 13:22:33,686:INFO:plot_model() successfully completed......................................
2025-08-09 13:22:37,465:INFO:Initializing plot_model()
2025-08-09 13:22:37,465:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-09 13:22:37,465:INFO:Checking exceptions
2025-08-09 13:22:37,899:INFO:Preloading libraries
2025-08-09 13:22:37,915:INFO:Copying training dataset
2025-08-09 13:22:37,915:INFO:Plot type: auc
2025-08-09 13:22:42,748:INFO:Fitting Model
2025-08-09 13:22:42,784:INFO:Scoring test/hold-out set
2025-08-09 13:22:42,886:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:22:42,886:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:22:42,886:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:22:43,300:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:22:43,301:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:22:43,301:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:22:44,539:INFO:Visual Rendered Successfully
2025-08-09 13:22:45,095:INFO:plot_model() successfully completed......................................
2025-08-09 13:22:52,079:INFO:Initializing finalize_model()
2025-08-09 13:22:52,079:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-08-09 13:22:52,081:INFO:Finalizing LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-09 13:22:52,190:INFO:Initializing create_model()
2025-08-09 13:22:52,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-08-09 13:22:52,190:INFO:Checking exceptions
2025-08-09 13:22:52,190:INFO:Importing libraries
2025-08-09 13:22:52,190:INFO:Copying training dataset
2025-08-09 13:22:52,208:INFO:Defining folds
2025-08-09 13:22:52,208:INFO:Declaring metric variables
2025-08-09 13:22:52,208:INFO:Importing untrained model
2025-08-09 13:22:52,208:INFO:Declaring custom model
2025-08-09 13:22:52,224:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-09 13:22:52,224:INFO:Cross validation set to False
2025-08-09 13:22:52,224:INFO:Fitting Model
2025-08-09 13:23:00,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:23:00,897:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:23:00,897:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:23:01,590:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-08-09 13:23:01,606:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:23:01,606:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:23:01,606:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:23:01,622:INFO:[LightGBM] [Info] Number of positive: 55776, number of negative: 656724
2025-08-09 13:23:01,792:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,127613 seconds.
2025-08-09 13:23:01,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-08-09 13:23:01,808:INFO:[LightGBM] [Info] Total Bins 624
2025-08-09 13:23:01,808:INFO:[LightGBM] [Info] Number of data points in the train set: 712500, number of used features: 29
2025-08-09 13:23:01,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,078282 -> initscore=-2,465920
2025-08-09 13:23:01,808:INFO:[LightGBM] [Info] Start training from score -2,465920
2025-08-09 13:23:03,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,957:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:03,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:03,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,125:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,258:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,419:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,721:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:04,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-08-09 13:23:04,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-08-09 13:23:05,036:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.3,
                                max_depth=-1, min_child_samples=71,
                                min_child_weight=0.001, min_split_gain=0.8,
                                n_estimators=100, n_jobs=-1, num_leaves=6,
                                objective=None, random_state=6271,
                                reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-08-09 13:23:05,036:INFO:create_model() successfully completed......................................
2025-08-09 13:23:05,336:INFO:_master_model_container: 3
2025-08-09 13:23:05,336:INFO:_display_container: 3
2025-08-09 13:23:05,383:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.3,
                                max_depth=-1, min_child_samples=71,
                                min_child_weight=0.001, min_split_gain=0.8,
                                n_estimators=100, n_jobs=-1, num_leaves=6,
                                objective=None, random_state=6271,
                                reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-08-09 13:23:05,383:INFO:finalize_model() successfully completed......................................
2025-08-09 13:27:53,310:INFO:Initializing save_model()
2025-08-09 13:27:53,310:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.3,
                                max_depth=-1, min_child_samples=71,
                                min_child_weight=0.001, min_split_gain=0.8,
                                n_estimators=100, n_jobs=-1, num_leaves=6,
                                objective=None, random_state=6271,
                                reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=model_final_pycaret, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\nobre\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-08-09 13:27:53,310:INFO:Adding model into prep_pipe
2025-08-09 13:27:53,310:WARNING:Only Model saved as it was a pipeline.
2025-08-09 13:27:53,639:INFO:model_final_pycaret.pkl saved in current working directory
2025-08-09 13:27:53,717:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.3,
                                max_depth=-1, min_child_samples=71,
                                min_child_weight=0.001, min_split_gain=0.8,
                                n_estimators=100, n_jobs=-1, num_leaves=6,
                                objective=None, random_state=6271,
                                reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-08-09 13:27:53,717:INFO:save_model() successfully completed......................................
2025-08-09 13:30:43,499:INFO:Initializing plot_model()
2025-08-09 13:30:43,499:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-09 13:30:43,499:INFO:Checking exceptions
2025-08-09 13:30:43,942:INFO:Preloading libraries
2025-08-09 13:30:43,942:INFO:Copying training dataset
2025-08-09 13:30:43,942:INFO:Plot type: pr
2025-08-09 13:30:50,443:INFO:Fitting Model
2025-08-09 13:30:50,476:INFO:Scoring test/hold-out set
2025-08-09 13:30:50,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:30:50,617:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:30:50,617:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:30:50,994:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:30:50,994:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:30:50,994:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:30:52,933:INFO:Visual Rendered Successfully
2025-08-09 13:31:16,181:INFO:plot_model() successfully completed......................................
2025-08-09 13:33:00,715:INFO:Initializing plot_model()
2025-08-09 13:33:00,715:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=100, n_jobs=-1, num_leaves=6, objective=None,
               random_state=6271, reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-09 13:33:00,715:INFO:Checking exceptions
2025-08-09 13:33:01,057:INFO:Preloading libraries
2025-08-09 13:33:01,124:INFO:Copying training dataset
2025-08-09 13:33:01,125:INFO:Plot type: confusion_matrix
2025-08-09 13:33:05,619:INFO:Fitting Model
2025-08-09 13:33:05,642:INFO:Scoring test/hold-out set
2025-08-09 13:33:05,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:33:05,693:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:33:05,693:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:33:06,146:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-08-09 13:33:06,147:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-08-09 13:33:06,147:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-08-09 13:33:06,836:INFO:Visual Rendered Successfully
2025-08-09 13:33:07,154:INFO:plot_model() successfully completed......................................
2025-08-09 13:34:32,923:INFO:Initializing predict_model()
2025-08-09 13:34:32,924:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.3,
                                max_depth=-1, min_child_samples=71,
                                min_child_weight=0.001, min_split_gain=0.8,
                                n_estimators=100, n_jobs=-1, num_leaves=6,
                                objective=None, random_state=6271,
                                reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000253526A2520>)
2025-08-09 13:34:32,924:INFO:Checking exceptions
2025-08-09 13:34:32,924:INFO:Preloading libraries
2025-08-09 13:35:13,805:INFO:Initializing predict_model()
2025-08-09 13:35:13,806:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002533D536690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.3,
                                max_depth=-1, min_child_samples=71,
                                min_child_weight=0.001, min_split_gain=0.8,
                                n_estimators=100, n_jobs=-1, num_leaves=6,
                                objective=None, random_state=6271,
                                reg_alpha=0.4, reg_lambda=0.4, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000253526C3CE0>)
2025-08-09 13:35:13,806:INFO:Checking exceptions
2025-08-09 13:35:13,806:INFO:Preloading libraries
2025-08-09 13:35:13,809:INFO:Set up data.
2025-08-09 13:35:13,903:INFO:Set up index.
